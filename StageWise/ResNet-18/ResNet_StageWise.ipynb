{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbca94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae62f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "['stage1', 'stage2', 'stage3', 'stage4', 'stage5', 'stage6', 'stage7', 'stage8', 'stage9']\n",
      "Image batch dimensions: torch.Size([128, 1, 300, 300])\n",
      "Image label dimensions: torch.Size([128])\n",
      "Class labels of 10 examples: tensor([6, 2, 2, 4, 3, 7, 4, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((300,300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "])\n",
    "#dataloader\n",
    "train_path = r'C:\\Datasets\\Train_set'\n",
    "test_path = r'C:\\Datasets\\Test_set'\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d0d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(torch.nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(torch.nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion=4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, zero_init_residual=False, groups=1,\n",
    "                 width_per_group=64, replace_stride_with_dilation=None, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = torch.nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                                     bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (torch.nn.BatchNorm2d, torch.nn.GroupNorm)):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    torch.nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    torch.nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks,\n",
    "                    stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = torch.nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09aeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77626 23645\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, layers=[2,2,2,2], num_classes=9).to(device)\n",
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff20df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6607ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "best_accuracy= 0.0\n",
    "test_accuracy=0.0\n",
    "train_accuracy=0.0\n",
    "train_loss=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f82fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(start_epochs, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred):\n",
    "    #Model training and saving best model\n",
    "\n",
    "    for epoch in range(start_epochs, num_epochs+1):\n",
    "\n",
    "        #Evaluation and training on training dataset\n",
    "        model.train()\n",
    "\n",
    "        for i, (images,labels) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images=Variable(images.cuda())\n",
    "                labels=Variable(labels.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=loss_function(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss+= loss.cpu().data*images.size(0)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "\n",
    "            train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "        train_accuracy=train_accuracy/train_count\n",
    "        train_loss=train_loss/train_count\n",
    "\n",
    "        # Evaluation on testing dataset\n",
    "        model.eval()\n",
    "\n",
    "        for i, (images,labels) in enumerate(test_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images=Variable(images.cuda())\n",
    "                labels=Variable(labels.cuda())\n",
    "\n",
    "            outputs=model(images)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "            test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            output = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "        test_accuracy=test_accuracy/test_count\n",
    "\n",
    "        print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        checkpoint = {\n",
    "                'start_epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'train_loss': train_loss,\n",
    "                'train_losses':train_losses,\n",
    "                'test_accuracies': test_accuracies,\n",
    "                'y_true': y_true,\n",
    "                'y_pred': y_pred\n",
    "        }\n",
    "        save_ckp(checkpoint, False, checkpoint_path='current_checkpoint_resnet18_stage.pt', best_model_path='best_checkpoint_resnet18_stage.model')\n",
    "        #Save the best model\n",
    "        if test_accuracy>best_accuracy:\n",
    "            torch.save(model.state_dict(),'best_checkpoint_resnet18_stage.model')\n",
    "            best_accuracy=test_accuracy\n",
    "            checkpoint['best_accuracy']=best_accuracy\n",
    "            save_ckp(checkpoint, True, checkpoint_path='current_checkpoint_resnet18_stage.pt', best_model_path='best_checkpoint_resnet18_stage.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0b61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    train_accuracy = checkpoint['train_accuracy']\n",
    "    test_accuracy = checkpoint['test_accuracy']\n",
    "    train_loss = checkpoint['train_loss']    \n",
    "    train_losses = checkpoint['train_losses']    \n",
    "    test_accuracies = checkpoint['test_accuracies']   \n",
    "    start_epoch = checkpoint['start_epoch']\n",
    "    y_true = checkpoint['y_true']\n",
    "    y_pred = checkpoint['y_pred']\n",
    "    return model, optimizer,start_epoch,best_accuracy, train_accuracy,test_accuracy,train_loss.item(),train_losses,test_accuracies,y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce150f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_true,y_pred):\n",
    "     # constant for classes\n",
    "    #classes = ('L4', 'day1', 'day10', 'day11', 'day12', 'day13', 'day14', 'day15', 'day16', 'day17', 'day18', 'day19', 'day2', 'day20', 'day21', 'day3', 'day4', 'day5', 'day6', 'day7', 'day8', 'day9', 'others')\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes],\n",
    "                         columns = [i for i in classes])\n",
    "    plt.figure(figsize = (12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dded7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_curve_train_losses(train_losses):\n",
    "    plt.plot(train_losses,'-o')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('losses')\n",
    "    plt.legend(['Train'])\n",
    "    plt.title('Train Losses Per Epoch')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def learn_curve_test_accuracies(test_accuracies):\n",
    "    plt.plot(test_accuracies,'-r')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('test_accuracy')\n",
    "    plt.legend(['Test Accuracy'])\n",
    "    plt.title('Test Accuracy Per Epoch')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11894c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: tensor(1.4728) Train Accuracy: 0.40367917965630074 Test Accuracy: 0.1631634595051808\n",
      "Epoch: 2 Train Loss: tensor(0.9995) Train Accuracy: 0.609079479545251 Test Accuracy: 0.5110663211444071\n",
      "Epoch: 3 Train Loss: tensor(0.6461) Train Accuracy: 0.7586067693746882 Test Accuracy: 0.3175094551203698\n",
      "Epoch: 4 Train Loss: tensor(0.4877) Train Accuracy: 0.8205080592426426 Test Accuracy: 0.40796436918820556\n",
      "Epoch: 5 Train Loss: tensor(0.3908) Train Accuracy: 0.8579190027575715 Test Accuracy: 0.5780252892522388\n",
      "Epoch: 6 Train Loss: tensor(0.3336) Train Accuracy: 0.8785311354314632 Test Accuracy: 0.6697220564723727\n",
      "Epoch: 7 Train Loss: tensor(0.2816) Train Accuracy: 0.900225163361959 Test Accuracy: 0.3914007072132152\n",
      "Epoch: 8 Train Loss: tensor(0.2532) Train Accuracy: 0.9094878033798388 Test Accuracy: 0.7218604948491103\n",
      "Epoch: 9 Train Loss: tensor(0.2216) Train Accuracy: 0.9217647371731557 Test Accuracy: 0.5987194696762466\n",
      "Epoch: 10 Train Loss: tensor(0.2038) Train Accuracy: 0.927987037393878 Test Accuracy: 0.6943370149913164\n",
      "Epoch: 11 Train Loss: tensor(0.1774) Train Accuracy: 0.9370948907200861 Test Accuracy: 0.6191877495037001\n",
      "Epoch: 12 Train Loss: tensor(0.1730) Train Accuracy: 0.9396199352651265 Test Accuracy: 0.7482604858426519\n",
      "Epoch: 13 Train Loss: tensor(0.1525) Train Accuracy: 0.9468984569594628 Test Accuracy: 0.36780495920853634\n",
      "Epoch: 14 Train Loss: tensor(0.1458) Train Accuracy: 0.9495394184739256 Test Accuracy: 0.7551857815588585\n",
      "Epoch: 15 Train Loss: tensor(0.1386) Train Accuracy: 0.9509436212018972 Test Accuracy: 0.19622563695417886\n",
      "Epoch: 16 Train Loss: tensor(0.1232) Train Accuracy: 0.9567535483423234 Test Accuracy: 0.6744849323593552\n",
      "Epoch: 17 Train Loss: tensor(0.1249) Train Accuracy: 0.9571014447936046 Test Accuracy: 0.626292006129514\n",
      "Epoch: 18 Train Loss: tensor(0.1115) Train Accuracy: 0.9615071896200346 Test Accuracy: 0.5434394710089291\n",
      "Epoch: 19 Train Loss: tensor(0.1118) Train Accuracy: 0.9617777742919847 Test Accuracy: 0.6849035076959615\n",
      "Epoch: 20 Train Loss: tensor(0.1067) Train Accuracy: 0.9630015945401579 Test Accuracy: 0.7232685516391497\n",
      "Epoch: 21 Train Loss: tensor(0.1011) Train Accuracy: 0.9645603663926332 Test Accuracy: 0.7653932445993503\n",
      "Epoch: 22 Train Loss: tensor(0.1021) Train Accuracy: 0.9649726194878828 Test Accuracy: 0.5946189635544343\n",
      "Epoch: 23 Train Loss: tensor(0.0981) Train Accuracy: 0.9664412049135533 Test Accuracy: 0.7834465899329056\n",
      "Epoch: 24 Train Loss: tensor(0.0958) Train Accuracy: 0.9670724556360616 Test Accuracy: 0.7850616809722957\n",
      "Epoch: 25 Train Loss: tensor(0.0924) Train Accuracy: 0.967961341205983 Test Accuracy: 0.5805787719044606\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477ca6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Train Loss: tensor(0.0883) Train Accuracy: 0.9700740468572541 Test Accuracy: 0.672978666896676\n",
      "Epoch: 27 Train Loss: tensor(0.0854) Train Accuracy: 0.9711175388922121 Test Accuracy: 0.6750548944244829\n",
      "Epoch: 28 Train Loss: tensor(0.0893) Train Accuracy: 0.9689662112892445 Test Accuracy: 0.4116166231716822\n",
      "Epoch: 29 Train Loss: tensor(0.0815) Train Accuracy: 0.9719677552136047 Test Accuracy: 0.7445299901299713\n",
      "Epoch: 30 Train Loss: tensor(0.0806) Train Accuracy: 0.9720322052888878 Test Accuracy: 0.7733450847955226\n",
      "Epoch: 31 Train Loss: tensor(0.0794) Train Accuracy: 0.973011259529092 Test Accuracy: 0.7730079655354111\n",
      "Epoch: 32 Train Loss: tensor(0.0803) Train Accuracy: 0.9722640998023797 Test Accuracy: 0.7108806516373668\n",
      "Epoch: 33 Train Loss: tensor(0.0767) Train Accuracy: 0.9736553766019093 Test Accuracy: 0.7852277809537592\n",
      "Epoch: 34 Train Loss: tensor(0.0796) Train Accuracy: 0.9728051639318862 Test Accuracy: 0.7889526423252676\n",
      "Epoch: 35 Train Loss: tensor(0.0719) Train Accuracy: 0.9754331384479934 Test Accuracy: 0.7732623790502146\n",
      "Epoch: 36 Train Loss: tensor(0.0761) Train Accuracy: 0.973887298497133 Test Accuracy: 0.7422192117732734\n",
      "Epoch: 37 Train Loss: tensor(0.0768) Train Accuracy: 0.9732946936245394 Test Accuracy: 0.7747406309668756\n",
      "Epoch: 38 Train Loss: tensor(0.0702) Train Accuracy: 0.976012847431191 Test Accuracy: 0.7231877665735236\n",
      "Epoch: 39 Train Loss: tensor(0.0734) Train Accuracy: 0.9747504188396597 Test Accuracy: 0.26676773896242645\n",
      "Epoch: 40 Train Loss: tensor(0.0715) Train Accuracy: 0.9756650445780903 Test Accuracy: 0.6771100345840119\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c48506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 Train Loss: tensor(0.0712) Train Accuracy: 0.9754460575714913 Test Accuracy: 0.7973219331797244\n",
      "Epoch: 42 Train Loss: tensor(0.0668) Train Accuracy: 0.9776746894862233 Test Accuracy: 0.7725437649369076\n",
      "Epoch: 43 Train Loss: tensor(0.0692) Train Accuracy: 0.9763091963348555 Test Accuracy: 0.6718026028236387\n",
      "Epoch: 44 Train Loss: tensor(0.0672) Train Accuracy: 0.9774814663797741 Test Accuracy: 0.8070912160119613\n",
      "Epoch: 45 Train Loss: tensor(0.0699) Train Accuracy: 0.976064430493216 Test Accuracy: 0.7634090543969554\n",
      "Epoch: 46 Train Loss: tensor(0.0663) Train Accuracy: 0.9775458746351802 Test Accuracy: 0.7316034429712158\n",
      "Epoch: 47 Train Loss: tensor(0.0650) Train Accuracy: 0.97758454056469 Test Accuracy: 0.5302064539413395\n",
      "Epoch: 48 Train Loss: tensor(0.0662) Train Accuracy: 0.9774814828091176 Test Accuracy: 0.6726381986235542\n",
      "Epoch: 49 Train Loss: tensor(0.0639) Train Accuracy: 0.9779581259047588 Test Accuracy: 0.6257421289151458\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67551f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 80\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbca94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae62f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "['stage1', 'stage2', 'stage3', 'stage4', 'stage5', 'stage6', 'stage7', 'stage8', 'stage9']\n",
      "Image batch dimensions: torch.Size([128, 1, 300, 300])\n",
      "Image label dimensions: torch.Size([128])\n",
      "Class labels of 10 examples: tensor([7, 6, 6, 5, 4, 3, 1, 5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((300,300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "])\n",
    "#dataloader\n",
    "train_path = r'C:\\Datasets\\Train_set'\n",
    "test_path = r'C:\\Datasets\\Test_set'\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d0d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(torch.nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(torch.nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion=4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, zero_init_residual=False, groups=1,\n",
    "                 width_per_group=64, replace_stride_with_dilation=None, norm_layer=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = torch.nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                                     bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (torch.nn.BatchNorm2d, torch.nn.GroupNorm)):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    torch.nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    torch.nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks,\n",
    "                    stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = torch.nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09aeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77626 23645\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, layers=[2,2,2,2], num_classes=9).to(device)\n",
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff20df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6607ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "best_accuracy= 0.0\n",
    "test_accuracy=0.0\n",
    "train_accuracy=0.0\n",
    "train_loss=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f82fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(start_epochs, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred):\n",
    "    #Model training and saving best model\n",
    "\n",
    "    for epoch in range(start_epochs, num_epochs+1):\n",
    "\n",
    "        #Evaluation and training on training dataset\n",
    "        model.train()\n",
    "\n",
    "        for i, (images,labels) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images=Variable(images.cuda())\n",
    "                labels=Variable(labels.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=loss_function(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss+= loss.cpu().data*images.size(0)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "\n",
    "            train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "        train_accuracy=train_accuracy/train_count\n",
    "        train_loss=train_loss/train_count\n",
    "\n",
    "        # Evaluation on testing dataset\n",
    "        model.eval()\n",
    "\n",
    "        for i, (images,labels) in enumerate(test_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images=Variable(images.cuda())\n",
    "                labels=Variable(labels.cuda())\n",
    "\n",
    "            outputs=model(images)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "            test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            output = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "        test_accuracy=test_accuracy/test_count\n",
    "\n",
    "        print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        checkpoint = {\n",
    "                'start_epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'train_loss': train_loss,\n",
    "                'train_losses':train_losses,\n",
    "                'test_accuracies': test_accuracies,\n",
    "                'y_true': y_true,\n",
    "                'y_pred': y_pred\n",
    "        }\n",
    "        save_ckp(checkpoint, False, checkpoint_path='current_checkpoint_resnet18_stage.pt', best_model_path='best_checkpoint_resnet18_stage.model')\n",
    "        #Save the best model\n",
    "        if test_accuracy>best_accuracy:\n",
    "            torch.save(model.state_dict(),'best_checkpoint_resnet18_stage.model')\n",
    "            best_accuracy=test_accuracy\n",
    "            checkpoint['best_accuracy']=best_accuracy\n",
    "            save_ckp(checkpoint, True, checkpoint_path='current_checkpoint_resnet18_stage.pt', best_model_path='best_checkpoint_resnet18_stage.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0b61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    train_accuracy = checkpoint['train_accuracy']\n",
    "    test_accuracy = checkpoint['test_accuracy']\n",
    "    train_loss = checkpoint['train_loss']    \n",
    "    train_losses = checkpoint['train_losses']    \n",
    "    test_accuracies = checkpoint['test_accuracies']   \n",
    "    start_epoch = checkpoint['start_epoch']\n",
    "    y_true = checkpoint['y_true']\n",
    "    y_pred = checkpoint['y_pred']\n",
    "    return model, optimizer,start_epoch,best_accuracy, train_accuracy,test_accuracy,train_loss.item(),train_losses,test_accuracies,y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce150f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_true,y_pred):\n",
    "     # constant for classes\n",
    "    #classes = ('L4', 'day1', 'day10', 'day11', 'day12', 'day13', 'day14', 'day15', 'day16', 'day17', 'day18', 'day19', 'day2', 'day20', 'day21', 'day3', 'day4', 'day5', 'day6', 'day7', 'day8', 'day9', 'others')\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes],\n",
    "                         columns = [i for i in classes])\n",
    "    plt.figure(figsize = (12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dded7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_curve_train_losses(train_losses):\n",
    "    plt.plot(train_losses,'-o')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('losses')\n",
    "    plt.legend(['Train'])\n",
    "    plt.title('Train Losses Per Epoch')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def learn_curve_test_accuracies(test_accuracies):\n",
    "    plt.plot(test_accuracies,'-r')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('test_accuracy')\n",
    "    plt.legend(['Test Accuracy'])\n",
    "    plt.title('Test Accuracy Per Epoch')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11894c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: tensor(1.5698) Train Accuracy: 0.36630768041635536 Test Accuracy: 0.26601818566293084\n",
      "Epoch: 2 Train Loss: tensor(1.2360) Train Accuracy: 0.5065746825506972 Test Accuracy: 0.3094635660048916\n",
      "Epoch: 3 Train Loss: tensor(0.8533) Train Accuracy: 0.6720751626347171 Test Accuracy: 0.19662970875728505\n",
      "Epoch: 4 Train Loss: tensor(0.5907) Train Accuracy: 0.7777120046783633 Test Accuracy: 0.11144836666139807\n",
      "Epoch: 5 Train Loss: tensor(0.4511) Train Accuracy: 0.8329139426481421 Test Accuracy: 0.5959869506604636\n",
      "Epoch: 6 Train Loss: tensor(0.3725) Train Accuracy: 0.8640897755126201 Test Accuracy: 0.6791962777310493\n",
      "Epoch: 7 Train Loss: tensor(0.3154) Train Accuracy: 0.8857968218093875 Test Accuracy: 0.3652645039660703\n",
      "Epoch: 8 Train Loss: tensor(0.2672) Train Accuracy: 0.9044119985162421 Test Accuracy: 0.4209078141046295\n",
      "Epoch: 9 Train Loss: tensor(0.2372) Train Accuracy: 0.9156842348182119 Test Accuracy: 0.73298460172612\n",
      "Epoch: 10 Train Loss: tensor(0.1975) Train Accuracy: 0.9300352418549818 Test Accuracy: 0.15723125331366994\n",
      "Epoch: 11 Train Loss: tensor(0.1782) Train Accuracy: 0.9369145651616965 Test Accuracy: 0.743969432491153\n",
      "Epoch: 12 Train Loss: tensor(0.1693) Train Accuracy: 0.9405732217886424 Test Accuracy: 0.3990587426277222\n",
      "Epoch: 13 Train Loss: tensor(0.1440) Train Accuracy: 0.9502349802027901 Test Accuracy: 0.6926791735564655\n",
      "Epoch: 14 Train Loss: tensor(0.1366) Train Accuracy: 0.9531207357712649 Test Accuracy: 0.5314735749280421\n",
      "Epoch: 15 Train Loss: tensor(0.1275) Train Accuracy: 0.9551304088930997 Test Accuracy: 0.39456677832839615\n",
      "Epoch: 16 Train Loss: tensor(0.1224) Train Accuracy: 0.9573977163631888 Test Accuracy: 0.5915582392378231\n",
      "Epoch: 17 Train Loss: tensor(0.1122) Train Accuracy: 0.9612624300842033 Test Accuracy: 0.7866183784410758\n",
      "Epoch: 18 Train Loss: tensor(0.1052) Train Accuracy: 0.9640836995649665 Test Accuracy: 0.4934991168694625\n",
      "Epoch: 19 Train Loss: tensor(0.0975) Train Accuracy: 0.9657841970950399 Test Accuracy: 0.48600099383027573\n",
      "Epoch: 20 Train Loss: tensor(0.0969) Train Accuracy: 0.9663123925514272 Test Accuracy: 0.6769501374918093\n",
      "Epoch: 21 Train Loss: tensor(0.0884) Train Accuracy: 0.9695329697832241 Test Accuracy: 0.2981466250851128\n",
      "Epoch: 22 Train Loss: tensor(0.0924) Train Accuracy: 0.9680773134384071 Test Accuracy: 0.252158940436671\n",
      "Epoch: 23 Train Loss: tensor(0.0881) Train Accuracy: 0.9696489330548198 Test Accuracy: 0.4459400363265146\n",
      "Epoch: 24 Train Loss: tensor(0.0829) Train Accuracy: 0.9714911195853587 Test Accuracy: 0.6902704986270386\n",
      "Epoch: 25 Train Loss: tensor(0.0813) Train Accuracy: 0.9721481396841212 Test Accuracy: 0.4574620541551545\n",
      "Epoch: 26 Train Loss: tensor(0.0804) Train Accuracy: 0.971813208823586 Test Accuracy: 0.7455046505415163\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 Train Loss: tensor(0.0774) Train Accuracy: 0.973294666905532 Test Accuracy: 0.4351340877416173\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 35\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7aa3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 Train Loss: tensor(0.0686) Train Accuracy: 0.976541020980946 Test Accuracy: 0.6964447085678892\n",
      "Epoch: 29 Train Loss: tensor(0.0732) Train Accuracy: 0.97476330792545 Test Accuracy: 0.7044912854602906\n",
      "Epoch: 30 Train Loss: tensor(0.0747) Train Accuracy: 0.9749694015318053 Test Accuracy: 0.61381706455003\n",
      "Epoch: 31 Train Loss: tensor(0.0696) Train Accuracy: 0.9760772804137986 Test Accuracy: 0.19609278143643688\n",
      "Epoch: 32 Train Loss: tensor(0.0721) Train Accuracy: 0.9755620034174171 Test Accuracy: 0.7792850959095553\n",
      "Epoch: 33 Train Loss: tensor(0.0671) Train Accuracy: 0.9767729312601887 Test Accuracy: 0.7963958251256463\n",
      "Epoch: 34 Train Loss: tensor(0.0662) Train Accuracy: 0.9774299432268989 Test Accuracy: 0.6087035904345581\n",
      "Epoch: 35 Train Loss: tensor(0.0647) Train Accuracy: 0.9778937138322626 Test Accuracy: 0.33282337507254955\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 35\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ac0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"current_checkpoint_resnet18_stage.pt\"):\n",
    "    ckp_path = \"current_checkpoint_resnet18_stage.pt\"\n",
    "    model, optimizer, start_epoch, best_accuracy, train_accuracy,test_accuracy,train_loss,train_losses,test_accuracies,y_true,y_pred  = load_ckp(ckp_path, model, optimizer)\n",
    "    train_test(start_epoch, best_accuracy,train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)\n",
    "else:\n",
    "    train_test(1,best_accuracy, train_accuracy,test_accuracy,train_loss, train_losses, test_accuracies,y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a52e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
